# CS-370

In the final project for CS-370, we were tasked with building the qtrain() method, which would use Deep Q learning to train an intelligent agent to traverse a given maze to find a 'treasure' cell. The code in this method is meant to initialize a state for the agent, use a mixture of explotation and exploration to choose actions in each given state, and step through the previous step until a state failure or success is reached. This allows us to use the Epsilon Greedy strategy to allow for more exploration early on, then force the model to act based on its q-table once it has gathered enough information about the environment. 

Broadly speaking, as computer scientists entering the labour market in the modern day (2025 as of writing), we face heavy pressure to be familiar with artificial intelligence and incorporate it into our work (even where it is not applicable, in some cases). This class gave me a stronger understanding of artificial intelligence and the way it is trained and makes decisions based on probabilities, random number generation, or learned experience as calculated by a variety of formulae. 

Good computer science is generally considered to create processes that produce defined behaviour, are composed of atomic modules (easily modifiable parts that are only as large as necessary to perform their function), and, most importatntly,solve a problem. Artificial intelligence can sometimes be used to solve specific problems, like the operation of robotics in non-repeatable environmental conditions (ie, outside of a simple, unchanging manufacturing process),and is sometimes easily modifiable and applicable to only small portions of the whole solution. It is also, however, very difficult to argue that AI always produces defined behaviour during runtime. The process of training, optimizing, and creating neural network layers abstracts much of the policy from the programmer and makese it very difficult to guarantee specific output.
